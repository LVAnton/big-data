# Технологии хранения больших данных

**Выполнили:** Батаев Илья Сергеевич, Лапин Антон Владимирович  
**Источники данных:** Avito, hh.ru

---

## Лабораторная работа №1 “Работа с Airflow. ETL-процесс”

Реализация ETL-процесса для сбора и загрузки сырых данных в хранилище (слой ODS). Выбор и аргументация базы данных, оркестрация процессов с помощью Apache Airflow.

---

## Этапы выполнения

### 1. Развертывание инфраструктуры
*   Развернуть сервис **Airflow** в Docker-контейнере, используя [docker-compose](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html) конфигурацию из официальной документации.
*   Выбрать **3 различных сервиса для хранения данных** (например: S3, MongoDB, Oracle).
*   Добавить конфигурацию для развертывания выбранных хранилищ в `docker-compose.yml`.

### 2. Реализация ETL-процессов (DAGs)
*   Реализовать **не менее 3 различных ETL-процессов** (DAG-ов).
*   **Источники данных:**
    *   При нехватке данных на одной платформе, данные можно брать с нескольких (например: Ozon + Wildberries, Aviasales + Tutu.ru).
    *   Данные можно разделять логически в рамках одного источника: комментарии, товары, отзывы.
*   **Результат:** Данные должны быть выгружены во все выбранные базы данных.

### 3. Сравнительный анализ хранилищ
*   Провести **сравнительный анализ** выбранных хранилищ данных.
*   **Критерии сравнения** необходимо выбрать самостоятельно.
*   **Выбрать наиболее подходящее хранилище** для полученных данных.

---

## Требования к защите работы

### Необходимые материалы:
1.  **Отчет**, описывающий этапы выполнения работы.
2.  **Исходный код** ETL-процессов.
3.  **`docker-compose.yml`** файл.

### Условия демонстрации:
*   Рабочий **веб-интерфейс Apache Airflow**.
*   **Выгруженные данные** в базах данных.
*   **Сравнительный анализ** в виде графиков и/или таблиц.
